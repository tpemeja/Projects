# -*- coding: utf-8 -*-
"""TP3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Aq73ITusQu04FjGhVXu8VCulPV2Pjduc

# IF240 - Apprentissage et deep learning

## Practice 3: SVM 

By Aur√©lie Bugeau
Credits:  Vincent Lepetit

### Objectives
The objective of the practice is to apply SVM with different kernels. You will use the two folling 2 moons and 2 circles datasets.
"""

# Commented out IPython magic to ensure Python compatibility.
from sklearn.datasets import make_moons, make_circles
# %matplotlib inline
import matplotlib.pyplot as plt

moons_X,moons_y = make_moons(1500, noise=.05, random_state=0)
circles_X,circles_y = make_circles(1500, factor=.5, noise=.05)

plt.scatter(moons_X[:, 0], moons_X[:, 1], c=moons_y,s=50, cmap='viridis');
plt.show()
plt.scatter(circles_X[:, 0], circles_X[:, 1], c=circles_y,s=50, cmap='viridis');

"""### Question 1
Make sure you understand what _Xmoons_, _ymoons_, _Xcircles_, _ycircles_ contain exactly

Separate the data into training and test data with:
"""

import numpy as np
indices = np.random.permutation(len(moons_X))
moons_X_train = moons_X[indices[:-40]]
moons_y_train = moons_y[indices[:-40]]
moons_X_valid = moons_X[indices[-40:-20]]
moons_y_valid = moons_y[indices[-40:-20]]
moons_X_test  = moons_X[indices[-20:]]
moons_y_test  = moons_y[indices[-20:]]

circles_X_train = circles_X[indices[:-40]]
circles_y_train = circles_y[indices[:-40]]
circles_X_valid = circles_X[indices[-40:-20]]
circles_y_valid = circles_y[indices[-40:-20]]
circles_X_test  = circles_X[indices[-20:]]
circles_y_test  = circles_y[indices[-20:]]

"""## Linear SVM
### Question 2
Apply linear SVM to these data and print the accuracy on the test datasets.
"""

from sklearn import svm
svc_moon = svm.SVC(kernel='linear')
svc_moon.fit(moons_X_train,moons_y_train)

svc_circle = svm.SVC(kernel='linear')
svc_circle.fit(circles_X_train,circles_y_train)

"""### Question 3
Check the documentation at \url{http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC} to see how to change the parameter $C$, the weight between the classification score and the regularization term.

Use the validation sets to identify the optimal value for $C$ and print the value of the corresponding on the test set.
"""

X = [10**x for x in range(-3,3)]
params = {'C': X}

for k, v in params.items():
    for val in v:
        svc_moon = svm.SVC(kernel='linear')
        svc_moon.fit(moons_X_train,moons_y_train)
        svc_circle = svm.SVC(kernel='linear')
        svc_circle.fit(circles_X_train,circles_y_train)
        clf_moon = svc_moon.set_params(**{k: val})
        clf_circle = svc_circle.set_params(**{k: val})

        print("For C = ",val,":")
        print("Moon Accuracy : ",clf_moon.score(moons_X_valid,moons_y_valid))
        print("Circle Accuracy : ",clf_circle.score(circles_X_valid,circles_y_valid))
        print()

"""### Question 4
Let us visualize the result. For visualizing in 2D  the effect of an SVM classifier, you are given the following functions
"""

import matplotlib.pyplot as plt


def make_meshgrid(x, y, h=.02):
    """Create a mesh of points to plot in
    
    Parameters
    ----------
    x: data to base x-axis meshgrid on
    y: data to base y-axis meshgrid on
    h: stepsize for meshgrid, optional
    Returns
    -------
    xx, yy : ndarray
    """
    x_min, x_max = x.min() - 1, x.max() + 1
    y_min, y_max = y.min() - 1, y.max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))
    return xx, yy


def plot_contours(ax, clf, xx, yy, **params):
    """Plot the decision boundaries for a classifier.

    Parameters
    ----------
    ax: matplotlib axes object
    clf: a classifier
    xx: meshgrid ndarray
    yy: meshgrid ndarray
    params: dictionary of params to pass to contourf, optional
    """
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    out = ax.contourf(xx, yy, Z, **params)
    return out

"""The visualization functions can be used in the following way. Classification of every point on the meshgrid is made. Explain the result"""

Xtest=moons_X_train
ytest=moons_y_train

models = (svm.SVC(kernel='linear', C=1),
          svm.SVC(kernel='linear', C=10))
models = (clf.fit(Xtest, ytest) for clf in models)

# title for the plots
titles = ('SVC with linear kernel, C=1',
          'SVC with linear kernel, C=10')

# Set-up 2x2 grid for plotting.
fig, sub = plt.subplots(1,2)
plt.subplots_adjust(wspace=0.4, hspace=0.4)

X0, X1 = Xtest[:, 0], Xtest[:, 1]
xx, yy = make_meshgrid(X0, X1)

for clf, title, ax in zip(models, titles, sub.flatten()):
    plot_contours(ax, clf, xx, yy,
                  cmap=plt.cm.coolwarm, alpha=0.8)
    ax.scatter(X0, X1, c=ytest, cmap=plt.cm.coolwarm, s=20, edgecolors='k')
    ax.set_xlim(xx.min(), xx.max())
    ax.set_ylim(yy.min(), yy.max())
    ax.set_xlabel('Sepal length')
    ax.set_ylabel('Sepal width')
    ax.set_xticks(())
    ax.set_yticks(())
    ax.set_title(title)

plt.show()

"""## Non-Linear SVM
You can create a non-linear support vector machine classifier with Gaussian kernels. 
See if you can tune $C$ and $\gamma$, the standard deviation of the kernels to improve the classification results on the two datasets.
Next experiment with the polynomial kernel.
"""

models = (svm.SVC(kernel='poly', C=1),
          svm.SVC(kernel='poly', C=10))
models = (clf.fit(Xtest, ytest) for clf in models)

# title for the plots
titles = ('SVC with poly kernel, C=1',
          'SVC with poly kernel, C=10')

# Set-up 2x2 grid for plotting.
fig, sub = plt.subplots(1,2)
plt.subplots_adjust(wspace=0.4, hspace=0.4)

X0, X1 = Xtest[:, 0], Xtest[:, 1]
xx, yy = make_meshgrid(X0, X1)

for clf, title, ax in zip(models, titles, sub.flatten()):
    plot_contours(ax, clf, xx, yy,
                  cmap=plt.cm.coolwarm, alpha=0.8)
    ax.scatter(X0, X1, c=ytest, cmap=plt.cm.coolwarm, s=20, edgecolors='k')
    ax.set_xlim(xx.min(), xx.max())
    ax.set_ylim(yy.min(), yy.max())
    ax.set_xlabel('Sepal length')
    ax.set_ylabel('Sepal width')
    ax.set_xticks(())
    ax.set_yticks(())
    ax.set_title(title)

plt.show()