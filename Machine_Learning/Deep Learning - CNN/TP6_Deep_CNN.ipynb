{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "colab": {
      "name": "TP6-Deep-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfvwjlCSMybK"
      },
      "source": [
        "# CNNs\n",
        "Credits Charles Deledalle  \n",
        "Adapted by Aur√©lie Bugeau\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPV-69vUMybO"
      },
      "source": [
        "\n",
        "CNNs are specific artificial neural networks composed of *convolutional* layers, *maxpooling* operations, and\n",
        "*fully connected* layers.\n",
        "- Convolutional layers are like typical layers where the weight matrix has a specific structure that is relevant for signals and images.  \n",
        "They take as input $N$ images and produce as output $C$ images (called *feature maps* or *channels*).   \n",
        "They are parameterized by a collection of coeficients that defines a filter bank. Each filter performs a weighted average of its inputs within local sliding windows of size $K \\times K$  (pixels) where $K$ is a hyperparameter (a small odd number: 3, 5, 7, 9).  \n",
        "As for classical layers in neural networks, each feature map is next processed by an activation function such as  ReLU.  \n",
        "  \n",
        "  \n",
        "- Maxpooling operations reduce the dimensions of each feature map by picking the maximum value within local but non-overlapping sliding windows of size $L \\times L$ (pixels) where $L$ is another hyper- parameter (usually 2). Maxpooling does not introduce new parameters to be learned.  \n",
        "\n",
        "  \n",
        "  \n",
        "- Fully connected layers are standard layers where the weight matrix does not have a specific structure: each of the $N$ output units is connected to each of the $M$ input units."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdneCufPMybP"
      },
      "source": [
        "## 1 - Preparing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfiuQKkDMybQ"
      },
      "source": [
        "In this practice, you will experiment a CNNs on MNSIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnaMj5iPMybQ"
      },
      "source": [
        "# Load modules\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import MNISTtools\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PurfrftTMybU"
      },
      "source": [
        "Let us first load and normalize MNIST testing and training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDXhi3PXMybV"
      },
      "source": [
        "def normalize_MNIST_images(x):\n",
        "    return 2 * x.astype(np.float32) / 255. - 1\n",
        "\n",
        "xtrain, ltrain = MNISTtools.load(dataset = \"training\")\n",
        "xtrain = normalize_MNIST_images(xtrain)\n",
        "\n",
        "xtest, ltest = MNISTtools.load(dataset='testing')\n",
        "xtest = normalize_MNIST_images(xtest)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oiX0IoeMybY"
      },
      "source": [
        "#### Questions 1\n",
        "Torch expects that the input of a convolutional layer is stored in the following format\n",
        "  $$\n",
        "  \\texttt{Batch size} \\times \\texttt{Number of input channels} \\times \\texttt{Image height} \\times \\texttt{Image width}\n",
        "  $$\n",
        "  \n",
        "The number of input channels in our case is 1 because MNIST is composed of grayscale images. It would have been 3 if the images were in RGB color.\n",
        "In deeper layers, the number of input channels will be the number of input feature maps.\n",
        "\n",
        "Reorganise the tensors _xtrain_ and _xtest_ accordingly.\n",
        "Hint:\n",
        "  Reshape them first with shape $\\texttt{(28, 28, 1, 60000)}$ and $\\texttt{(28, 28, 1, 10000)}$\n",
        "  respectively and then use $\\texttt{np.moveaxis}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAZeA85UMybY",
        "outputId": "34f4e037-e4dd-4834-eb06-8f078039e317",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "xtrain = np.reshape(xtrain, (28,28,1,60000))\n",
        "xtrain = np.moveaxis(xtrain,-2,0)\n",
        "xtrain = np.moveaxis(xtrain,-1,0)\n",
        "print(xtrain.shape)\n",
        "\n",
        "xtest = np.reshape(xtest, (28,28,1,10000))\n",
        "xtest = np.moveaxis(xtest,-2,0)\n",
        "xtest = np.moveaxis(xtest,-1,0)\n",
        "print(xtest.shape)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 1, 28, 28)\n",
            "(10000, 1, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGLP93neMybb"
      },
      "source": [
        "Check that your data are well reorganized by making sure that `MNISTtools.show(xtrain[42, 0, :, :])` displays a digit that indeed corresponds to `ltrain[42]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stuYRpZxMybb",
        "outputId": "3b3c36a0-502c-40a1-baac-6b8844b6dcdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "MNISTtools.show(xtrain[42, 0, :, :])\n",
        "print(ltrain[42])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9Iqz3YtMybe",
        "outputId": "dd50b812-3a98-4ad2-b470-d621e74edec5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(ltrain.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im61l_5cMybg"
      },
      "source": [
        "Finally wrap all the data into torch Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pBWW9DdMybh"
      },
      "source": [
        "xtrain = torch.from_numpy(xtrain)\n",
        "ltrain = torch.from_numpy(ltrain)\n",
        "xtest = torch.from_numpy(xtest)\n",
        "ltest = torch.from_numpy(ltest)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icQ2LNtZMybk"
      },
      "source": [
        "## 2- Convolutional Neural Network (CNN) for MNIST classification\n",
        "\n",
        "Neural networks can be constructed using the _torch.nn_ package, which\n",
        "relies on _autograd_ differentiation tools.\n",
        "This package provides an implementation of CNNs as follows:\n",
        "\n",
        "* Convolutional layers can be created as `nn.Conv2d(N, C, K)`.\n",
        "  For input images of size $W \\times H$, the output feature maps have size $[W-K+1] \\times [H-K+1]$.\n",
        "* In PyTorch, maxpooling is implemented like any other non-linear function (such as\n",
        "  `RELU` or `softmax`.\n",
        "  For input images of size $W \\times H$, the output feature maps\n",
        "  have size $\\lceil W/L \\rceil \\times \\lceil H/L \\rceil$.\n",
        "* A fully connected layer can be created as `nn.Linear(M, N)`.\n",
        "\n",
        "#### Question 2 \n",
        "Our LeNet network will be composed successively of\n",
        "   1. a convolutional layer (i) connecting the input image to 6\n",
        "    feature maps with $5 \\times 5$ convolutions ($K = 5$) and followed\n",
        "    by ReLU and maxpooling (ii) ($L=2$),\n",
        "   2. a convolutional layer (iii) connecting the 6 input channels to 16\n",
        "    output channels with $5 \\times 5$ convolutions and followed\n",
        "    by ReLU and maxpooling (iv) ($L=2$),\n",
        "   3. a fully-connected layer connecting $16$ feature maps\n",
        "    to $120$ output units and followed by RELU,\n",
        "   4. a fully-connected layer connecting $120$ inputs\n",
        "    to $84$ output units and followed by RELU,\n",
        "   5. a final linear layer connecting $84$ inputs\n",
        "    to $10$ linear outputs (one for each of our digits).\n",
        "\n",
        "Determine the size of the feature maps after each convolution and maxpooling operation i.e. at points (i)-(iv) processing steps. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2VUeY4EMybk"
      },
      "source": [
        "#!Complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCKbCf0EMybl"
      },
      "source": [
        "#### Question 3\n",
        "Interpret and complete the following code initializing our LeNet network. \n",
        "\n",
        "Note that you just have to define the forward function, and the backward function (where gradients are computed) will be automatically defined for you using _autograd_.\n",
        "You can use any of the Torch tensor operations in the forward function.\n",
        "For more details, please refer to \\url{https://pytorch.org/docs/stable/nn.html}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cZ3jkXOMybl",
        "outputId": "80b0653b-46dd-4339-8dcc-8957e2e65ca8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# The neural networks class\n",
        "class LeNet(nn.Module):\n",
        "\n",
        "    # define our network structure\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6 , 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16 , 5)\n",
        "        self.fc1 = nn.Linear(16, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    # define one forward pass through the network\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (5, 5))\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "    # Thelper function to understand the dimensions\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:] # all dimensions except the batch dimension\n",
        "        return np.prod(size)\n",
        "\n",
        "net = LeNet()\n",
        "print(net)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LeNet(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=16, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4PU3fuDMybo"
      },
      "source": [
        "#### Question 4\n",
        "Run the following and interpret the results. What are the learnable parameters?  Are gradients going to be tracked by _autograd_ for all parameters?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bysO1k6QMybo",
        "outputId": "64307b43-157f-408f-ae8c-728d62312044",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for name, param in net.named_parameters():\n",
        "    print(name, param.size(), param.requires_grad)  "
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.weight torch.Size([6, 1, 5, 5]) True\n",
            "conv1.bias torch.Size([6]) True\n",
            "conv2.weight torch.Size([16, 6, 5, 5]) True\n",
            "conv2.bias torch.Size([16]) True\n",
            "fc1.weight torch.Size([120, 16]) True\n",
            "fc1.bias torch.Size([120]) True\n",
            "fc2.weight torch.Size([84, 120]) True\n",
            "fc2.bias torch.Size([84]) True\n",
            "fc3.weight torch.Size([10, 84]) True\n",
            "fc3.bias torch.Size([10]) True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CNsNUujMybr"
      },
      "source": [
        "#### Runnung a foward pass\n",
        "To run a forward pass of your initial network over your testing set, simply run the following code. \n",
        "\n",
        "Note that `with torch.no\\_grad()` is used to avoid tracking for\n",
        "gradient during testing and then save some computation time\n",
        "(refer to \\url{https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad}).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK61r8PSMybr"
      },
      "source": [
        "with torch.no_grad():\n",
        "    yinit = net(xtest) #equivalent to  yinit = net.forward(xtest)\n"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdpBX5J5Mybu"
      },
      "source": [
        "#### Question 5\n",
        "Run the following and interpret the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95gnx2bfMybu",
        "outputId": "a3a1d259-9bff-4e88-fec2-f6c0737d91c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "_, lpred = yinit.max(1)\n",
        "print(100 * (ltest == lpred).float().mean())"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(4.8800)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLzYVDasMybx"
      },
      "source": [
        "#! COmplete\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df1WhloPMyby"
      },
      "source": [
        "#### Question 6\n",
        "We will use (Mini-Batch) Stochastic Gradient Descent (SGD) with cross-entropy and momentum.\n",
        "Complete the following function.\n",
        "\n",
        "For more details, refer to\n",
        "\\url{https://pytorch.org/docs/stable/nn.html} and\n",
        "\\url{https://pytorch.org/docs/stable/optim.html}.\n",
        "Note that PyTorch's CrossEntropyLoss is the composition of a softmax activation with the standard cross-entropy loss.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyHcuzLIMyby"
      },
      "source": [
        "# T: number of epochs\n",
        "# B: minibatch size, \n",
        "# gamma: step size,\n",
        "# rho: momentum.\n",
        "def backprop_deep(xtrain, ltrain, net, T, B=100, gamma=.001, rho=.9):\n",
        "    N = xtrain.size()[0]        # Training set size\n",
        "    NB = 500   # Number of minibatches\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=rho)\n",
        "    for epoch in range(T):\n",
        "        running_loss = 0.0\n",
        "        shuffled_indices = np.random.permutation(range(N))\n",
        "        for k in range(NB):\n",
        "            # Extract k-th minibatch from xtrain and ltrain\n",
        "            minibatch_indices = shuffled_indices[B*k:min(B*(k+1), N)]\n",
        "            inputs = xtrain[minibatch_indices]\n",
        "            labels = ltrain[minibatch_indices]\n",
        "\n",
        "            # Initialize the gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward propogation\n",
        "            outputs = net(inputs) \n",
        "\n",
        "            # Error evaluation\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Back propogation\n",
        "            loss.backward()\n",
        "\n",
        "            # Optimize step\n",
        "            optimizer.step()\n",
        "\n",
        "            # Compute and print statistics\n",
        "            with torch.no_grad():\n",
        "                running_loss += loss\n",
        "            if k % 100 == 99:\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, k + 1, running_loss / 100))\n",
        "                running_loss = 0.0\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHebywFxMyb1"
      },
      "source": [
        "#### Question 7\n",
        "\n",
        "Run the function for 3 epochs, it may take several minutes.\n",
        "The loss per minibatch should decay as\n",
        "$2.30, 2.29, 2.27, 2.24, 2.15, 1.82, 1.07, 0.65, \\ldots$\n",
        "until $0.22$ (these are approximative values that slightly vary\n",
        "each time you reinitiate the network).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFlBa4vOMyb1",
        "outputId": "7e89e210-3760-49c1-8042-0fea1515e226",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "net = LeNet()\n",
        "backprop_deep(xtrain, ltrain, net, T=3)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 2.279\n",
            "[1,   200] loss: 1.484\n",
            "[1,   300] loss: 0.564\n",
            "[1,   400] loss: 0.367\n",
            "[1,   500] loss: 0.292\n",
            "[2,   100] loss: 0.227\n",
            "[2,   200] loss: 0.221\n",
            "[2,   300] loss: 0.201\n",
            "[2,   400] loss: 0.185\n",
            "[2,   500] loss: 0.165\n",
            "[3,   100] loss: 0.158\n",
            "[3,   200] loss: 0.136\n",
            "[3,   300] loss: 0.141\n",
            "[3,   400] loss: 0.145\n",
            "[3,   500] loss: 0.138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zh-TLd-Myb4"
      },
      "source": [
        "#### Question 8\n",
        "Re-evaluate the predictions of your trained network on the testing dataset.\n",
        "By how much did the accuracy improve compared to the initialization ? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3mOcc1zMyb4",
        "outputId": "e6656937-e78e-44b6-f4a6-a6e3a5f0b1db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "    yinit = net(xtest) #equivalent to  yinit = net.forward(xtest)\n",
        "_, lpred = yinit.max(1)\n",
        "print(100 * (ltest == lpred).float().mean())"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(96.7600)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}